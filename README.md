# Sign-Language-Detection
This is Sign Language Detection Model  which trained on MNIST training database using CNN and ANN machine leaning techniques.

The Sign Detection System is a computer vision-based project that aims to detect hand gestures and convert them into corresponding text or commands. The system uses image processing techniques to analyse the hand gesture captured by a camera, detect the shape and orientation of the hand, and recognize the sign language used in the gesture. 
The system is implemented using OpenCV and Python, and it uses a pre-trained Convolutional Neural Network (CNN) model for sign language detection.

This system is capable of detecting a wide range of sign languages, including American Sign Language (ASL). The system has been tested on a dataset of hand gestures and has achieved an accuracy of over 90%. The system can be used in various applications, including communication devices for the deaf and mute, automatic sign language translation systems, and gesture-based control systems for smart homes and appliances.

<img src="amer_sign2.png">

<br>
